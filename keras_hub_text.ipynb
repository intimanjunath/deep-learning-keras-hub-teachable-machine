{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8l0KIXwQyYTkqZEMgrtQ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/intimanjunath/deep-learning-keras-hub-teachable-machine/blob/main/keras_hub_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Easy Level"
      ],
      "metadata": {
        "id": "Q0cXfMTtlqxy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LToT7UMhhvq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data for binary sentiment classification\n",
        "texts_easy = [\n",
        "    \"I love this product!\",\n",
        "    \"This is the worst thing I've ever bought.\",\n",
        "    \"Not bad, could be better.\",\n",
        "    \"Absolutely fantastic service.\"\n",
        "]\n",
        "labels_easy = [1, 0, 1, 1]  # 1 = positive, 0 = negative"
      ],
      "metadata": {
        "id": "q7F7EmMelqRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer setup\n",
        "max_vocab = 1000\n",
        "max_len = 10\n",
        "tokenizer = Tokenizer(num_words=max_vocab, oov_token=\"<UNK>\")\n",
        "tokenizer.fit_on_texts(texts_easy)\n",
        "encoded = tokenizer.texts_to_sequences(texts_easy)\n",
        "padded = pad_sequences(encoded, maxlen=max_len, padding='post')"
      ],
      "metadata": {
        "id": "sZZDYBrJlyQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define simple embedding-based model\n",
        "model_easy = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=max_vocab, output_dim=16, input_length=max_len),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_easy.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_easy.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "0x6Z2bBelz1H",
        "outputId": "001cf374-8cbf-4b1d-ace6-cdfba983fec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model_easy.fit(padded, np.array(labels_easy), epochs=20, batch_size=2, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoKTHODhl1zA",
        "outputId": "08c0e0c7-3dac-4ebd-9713-c5d6942f4ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79f18c765b10>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test examples\n",
        "test_texts = [\"I really enjoyed this!\", \"Terrible experience.\"]\n",
        "test_seq = tokenizer.texts_to_sequences(test_texts)\n",
        "test_pad = pad_sequences(test_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "preds_easy = model_easy.predict(test_pad)\n",
        "print(\"\\n[Easy] Sentiment Predictions:\")\n",
        "for i, txt in enumerate(test_texts):\n",
        "    print(f\"Text: {txt} → Sentiment score: {preds_easy[i][0]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNSPFlTal3cn",
        "outputId": "a240e497-c720-4cb6-de3b-77cbfd360b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
            "\n",
            "[Easy] Sentiment Predictions:\n",
            "Text: I really enjoyed this! → Sentiment score: 0.59\n",
            "Text: Terrible experience. → Sentiment score: 0.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#intermediate"
      ],
      "metadata": {
        "id": "b3BICWTK4fcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This model fine-tunes BERT to predict sentiment from raw text.\n",
        "# We force the BERT preprocessor to run on CPU to avoid resource conflicts.\n",
        "\n",
        "# Sample training data.\n",
        "intermediate_sentences = [\n",
        "    \"I loved the movie. It was fantastic!\",\n",
        "    \"The film was boring and too long.\",\n",
        "    \"What an excellent performance!\",\n",
        "    \"Terrible movie. I hated it.\"\n",
        "]\n",
        "intermediate_labels = [1, 0, 1, 0]\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text  # Make sure this version is compatible with your TF version\n",
        "\n",
        "# Custom wrapper for BERT preprocessor.\n",
        "class WrappedBERTPreprocessor(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(WrappedBERTPreprocessor, self).__init__(**kwargs)\n",
        "        self.preprocessor_layer = hub.KerasLayer(\n",
        "            \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\",\n",
        "            name=\"bert_preprocess\"\n",
        "        )\n",
        "    def call(self, inputs):\n",
        "        # Force the preprocessor to run on CPU.\n",
        "        with tf.device(\"/CPU:0\"):\n",
        "            return self.preprocessor_layer(inputs)\n",
        "\n",
        "# Define the BERT sentiment model.\n",
        "input_text_bert = tf.keras.Input(shape=(), dtype=tf.string, name=\"input_text\")\n",
        "wrapped_preprocessor = WrappedBERTPreprocessor()(input_text_bert)\n",
        "encoder = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\",\n",
        "    trainable=True, name=\"bert_encoder\"\n",
        ")\n",
        "# Get the pooled output from the BERT encoder.\n",
        "encoder_outputs = encoder(wrapped_preprocessor)\n",
        "x_bert = encoder_outputs['pooled_output']\n",
        "x_bert = tf.keras.layers.Dropout(0.1)(x_bert)\n",
        "output_bert = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"classifier\")(x_bert)\n",
        "model_bert = tf.keras.Model(inputs=input_text_bert, outputs=output_bert, name=\"BERT_Sentiment_Model\")\n",
        "model_bert.build((None,))\n",
        "model_bert.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
        "                   loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model_bert.summary()\n",
        "\n",
        "# Train the BERT model.\n",
        "model_bert.fit(tf.constant(intermediate_sentences), np.array(intermediate_labels), epochs=2, batch_size=2)\n",
        "# Predict with the BERT model.\n",
        "preds_bert = model_bert.predict(tf.constant([\n",
        "    \"An amazing experience, I would watch it again.\",\n",
        "    \"It was a waste of time.\"\n",
        "]))\n",
        "print(\"\\nIntermediate Level Model Predictions:\")\n",
        "print(\"Prediction shape:\", preds_bert.shape, \"DType:\", preds_bert.dtype)\n",
        "print(\"Predicted sentiment probabilities (closer to 1 indicates positive sentiment):\")\n",
        "print(preds_bert)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acIG-hxZ7b6s",
        "outputId": "34072797-3c49-4e95-af6e-1381ea7715f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Intermediate Level: Fine-Tuning BERT for Sentiment Classification ===\n",
            "Model: \"BERT_Sentiment_Model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_text (InputLayer)        [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " wrapped_bert_preprocessor_2 (W  {'input_type_ids':   0          ['input_text[0][0]']             \n",
            " rappedBERTPreprocessor)        (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " bert_encoder (KerasLayer)      {'pooled_output': (  109482241   ['wrapped_bert_preprocessor_2[0][\n",
            "                                None, 768),                      0]',                             \n",
            "                                 'sequence_output':               'wrapped_bert_preprocessor_2[0][\n",
            "                                 (None, 128, 768),               1]',                             \n",
            "                                 'encoder_outputs':               'wrapped_bert_preprocessor_2[0][\n",
            "                                 [(None, 128, 768),              2]']                             \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'default': (None,                                                \n",
            "                                768)}                                                             \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 768)          0           ['bert_encoder[0][13]']          \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 1)            769         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 109,483,009\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/2\n",
            "2/2 [==============================] - 51s 6s/step - loss: 0.8951 - accuracy: 0.5000\n",
            "Epoch 2/2\n",
            "2/2 [==============================] - 8s 4s/step - loss: 0.5380 - accuracy: 0.7500\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "\n",
            "Intermediate Level Model Predictions:\n",
            "Prediction shape: (2, 1) DType: float32\n",
            "Predicted sentiment probabilities (closer to 1 indicates positive sentiment):\n",
            "[[0.32621172]\n",
            " [0.20140675]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#advance"
      ],
      "metadata": {
        "id": "5QfW8-By4maI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download required resources. We add 'punkt_tab' to resolve the error.\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker_tab')\n",
        "nltk.download('words')\n",
        "\n",
        "# Define a sample text.\n",
        "text_for_ner = (\n",
        "    \"Apple Inc. is looking at buying a startup in the U.K. for $1 billion. \"\n",
        "    \"Tim Cook, the CEO of Apple, stated that this acquisition will strengthen the company's market position.\"\n",
        ")\n",
        "\n",
        "# Tokenize the text into sentences.\n",
        "sentences = nltk.sent_tokenize(text_for_ner)\n",
        "\n",
        "# For each sentence, tokenize into words, perform POS tagging, and then perform NER.\n",
        "print(\"\\nDetected Named Entities:\")\n",
        "for sentence in sentences:\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "    tree = nltk.ne_chunk(pos_tags)\n",
        "    # Traverse the tree and print named entities.\n",
        "    for subtree in tree:\n",
        "        if hasattr(subtree, 'label'):\n",
        "            entity = \" \".join([token for token, pos in subtree.leaves()])\n",
        "            entity_type = subtree.label()\n",
        "            print(f\"{entity}: {entity_type}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-6chMoz7dbe",
        "outputId": "502fe29a-3a30-4d01-973d-02b262d3f1de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Advanced Level: Named Entity Recognition (NER) using NLTK ===\n",
            "\n",
            "Detected Named Entities:\n",
            "Apple: PERSON\n",
            "Inc.: ORGANIZATION\n",
            "Tim: PERSON\n",
            "Cook: GPE\n",
            "CEO: ORGANIZATION\n",
            "Apple: GPE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#expert"
      ],
      "metadata": {
        "id": "uXYboXyL4qTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install transformers if not already installed.\n",
        "!pip install transformers --quiet\n",
        "from transformers import pipeline\n",
        "\n",
        "# Create a summarization pipeline using T5-small.\n",
        "summarizer = pipeline(\"summarization\", model=\"t5-small\")\n",
        "# Provide a long text to summarize.\n",
        "text_to_summarize = (\n",
        "    \"Artificial intelligence (AI) is intelligence demonstrated by machines, \"\n",
        "    \"in contrast to the natural intelligence displayed by humans and animals. \"\n",
        "    \"Leading AI textbooks define the field as the study of 'intelligent agents': any device \"\n",
        "    \"that perceives its environment and takes actions that maximize its chance of successfully \"\n",
        "    \"achieving its goals. Colloquially, the term 'artificial intelligence' is often used to \"\n",
        "    \"describe machines (or computers) that mimic cognitive functions that humans associate with \"\n",
        "    \"the human mind, such as learning and problem-solving.\"\n",
        ")\n",
        "summary = summarizer(text_to_summarize, max_length=60, min_length=20, do_sample=False)\n",
        "print(\"\\nExpert Level Text Summarization Output:\")\n",
        "print(\"Summarized Text:\", summary[0]['summary_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBKxNA62JXER",
        "outputId": "9dfce5ae-24f4-46b9-ffff-7ced9b3e3542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Expert Level: Text Summarization with T5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Expert Level Text Summarization Output:\n",
            "Summarized Text: leading AI textbooks define the field as the study of 'intelligent agents' the term 'artificial intelligence' is often used to describe machines that mimic cognitive functions that humans associate with the human mind .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "BimEH_sN4T_2"
      }
    }
  ]
}